"""Randomized Causation Coefficient Model.

Author : David Lopez-Paz
Ref : Lopez-Paz, David and Muandet, Krikamol and Schölkopf, Bernhard and Tolstikhin, Ilya O,
     "Towards a Learning Theory of Cause-Effect Inference", ICML 2015.
"""

from sklearn.preprocessing import scale
from sklearn.ensemble import RandomForestClassifier as CLF
from sklearn.metrics import auc
import pandas
import numpy as np
from .model import PairwiseModel


def rp(k, s, d):
    return np.hstack((np.vstack([si * np.random.randn(k, d) for si in s]),
                      2 * np.pi * np.random.rand(k * len(s), 1))).T


def f1(x, w):
    return np.cos(np.dot(np.hstack((x, np.ones((x.shape[0], 1)))), w))


def score(y, p):
    return (auc(y == 1, p) + auc(y == -1, -p)) / 2


class RCC(PairwiseModel):
    """Randomized Causation Coefficient model.

    Ref : Lopez-Paz, David and Muandet, Krikamol and Schölkopf, Bernhard and Tolstikhin, Ilya O,
     "Towards a Learning Theory of Cause-Effect Inference", ICML 2015.
    """

    def __init__(self, **kwargs):
        """Initialize the model w/ its parameters.

        :param args: None
        :param kwargs: {K: number of randomized coefficients,
                        E: number of estimators,
                        L: number of min samples leaves of the estimator
                        max_depth: max depth of the model
                        n_jobs: number of jobs to be run on parallel}

        """
        np.random.seed(0)
        self.K = kwargs.pop('K', 333)
        self.E = kwargs.pop('E', 500)
        self.L = kwargs.pop('L', 20)
        self.n_jobs = kwargs.pop('n_jobs', 1)
        self.max_depth = kwargs.pop('max_depth', 1)

        self.params = {'random_state': 0, 'n_estimators': self.E, 'max_features': None,
                       'max_depth': self.max_depth, 'min_samples_leaf': self.L, 'verbose': 10, 'n_jobs': self.n_jobs}

        self.wx = rp(self.K, [0.15, 1.5, 15], 1)
        self.wy = rp(self.K, [0.15, 1.5, 15], 1)
        self.wz = rp(self.K, [0.15, 1.5, 15], 2)
        self.clf0 = None
        self.clf1 = None

    def fit(self, x_tr, y_tr):
        """Fit the model on pairwise data.

        :param x_tr: Input data - CEPC-format DataFrame containing pairs of variables
        :param y_tr: Targets
        :type x_tr: pandas.DataFrame
        :type y_tr: pandas.DataFrame
        """
        x_tr, y_tr, x_ab, y_ab = self.transform(x_tr, y_tr)
        self.fit_ftdata(x_tr, y_tr, x_ab, y_ab)

    def fit_ftdata(self, x_ft, y_ft, x_ab, y_ab):
        """Fit the model with featurized data as input.

        :param x_ft: x_featurized
        :param y_ft: y_featurized
        :param x_ab: x_inverse_featurized
        :param y_ab: y_inverse_featurized
        """
        self.clf0 = CLF(**self.params).fit(x_ft, y_ft != 0)  # causal or confounded?
        self.clf1 = CLF(**self.params).fit(x_ab, y_ab == 1)  # causal or anticausal?

    def featurize_row(self, row, reverse=False):
        x = scale(row['A'])[:, np.newaxis]
        y = scale(row['B'])[:, np.newaxis]
        if reverse:
            x, y = y, x
        d = np.hstack((f1(x, self.wx).mean(0), f1(y, self.wy).mean(0), f1(np.hstack((x, y)), self.wz).mean(0)))
        return d

    def featurize(self, data):
        ft_data = []
        ft_data_rev = []
        for idx, row in data.iterrows():
            ft_data.append(self.featurize_row(row))
            ft_data_rev.append(self.featurize_row(row, reverse=True))
        return np.vstack((np.array(ft_data), np.array(ft_data_rev)))

    def transform(self, x_tr, y_tr=None):
        """Featurize the data with the randomized coefficients.

        :param x_tr: Inputdata - CEPC-format DataFrame containing pairs of variables
        :param y_tr: Targets
        :type x_tr: pandas.DataFrame
        :type y_tr: pandas.DataFrame or array
        :return: Featurized data
        """
        x_tr = self.featurize(x_tr)
        print(x_tr.shape)
        x_ab, y_ab = None, None
        if y_tr:
            if type(y_tr) == pandas.DataFrame:
                y_tr = y_tr['Target'].as_matrix()
            y_tr = np.hstack((y_tr, -y_tr))

            x_ab = x_tr[(y_tr == 1) | (y_tr == -1)]
            y_ab = y_tr[(y_tr == 1) | (y_tr == -1)]

        print('Featurize Finished !')

        return x_tr, y_tr, x_ab, y_ab

    def predict_dataset(self, x_te):
        """Predict causal directions of a dataset. With input data as (X,Y).

            -1 is Y->X
             1 is X->Y
             # 0 is independent/confounding

        :param x_te: Inputdata - CEPC-format DataFrame containing pairs of variables
        :type x_te: pandas.DataFrame
        :return: Array containing probabilities of predictions
        :rtype: numpy.ndarray
        """
        if not self.clf0:
            print('Model has to be trained before doing any predictions')
            raise ValueError

        x_te, _, _, _ = self.transform(x_te)
        p_te = self.clf0.predict_dataset(x_te)[:, 0] * (2 * self.clf1.predict_dataset(x_te)[:, 0] - 1)
        p_te = (p_te[:len(p_te)//2] - p_te[len(p_te)//2:])/2
        return p_te

    def predict_proba(self, a, b):
        """Infer causal directions using the trained RCC model.

        :param a: Variable 1
        :param b: Variable 2
        :return: probability (Value : 1 if a->b and -1 if b->a)
        :rtype: float
        """
        if not self.clf0:
            print('Model has to be trained before doing any predictions')
            raise ValueError

        a = scale(a)
        b = scale(b)
        d = np.hstack((f1(a, self.wx).mean(0), f1(b, self.wy).mean(0), f1(np.hstack((a, b)), self.wz).mean(0)))
        p_te = self.clf0.predict_dataset(d)[:, 0] * (2 * self.clf1.predict_dataset(d)[:, 0] - 1)
        return p_te
