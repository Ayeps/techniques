{
 "metadata": {
  "name": "test_ml_spam"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Small Example of an Machine Learning Engine ready for OCP"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a small example of a machine learning engine that is built with python and `ticdat` and is ready for deployment on the Opalytics Cloud Platform. \n",
      "\n",
      "This example is built from [this](http://radimrehurek.com/data_science_python/) notebook demonstrating the use of `sklearn` to build a \"spam\"/\"ham\" classifier. Bear in mind that the math here is fairly complex, and also that the black box details of this math aren't the focus of this demonstration. Instead, we give an example of what an OCP ready engine might look like, and how the \"fit\" and \"predict\" modes can be tested in isolation.  So if you don't understand the full radimrehurek notebook don't worry about it. Just start by examining the `ml_spam.py` file and getting a general sense of how the math interacts with the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ml_spam import dataFactory, run, solnFactory\n",
      "from ticdat import LogFile"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First we load some data that we want fitted."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fit_data = dataFactory.csv.create_tic_dat(\"fit_me/\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The solve knows this data is ready to be fitted because of the parameter setting."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fit_data.parameters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "{'mode': _td:{'value': 'fit'}}"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we fit the data. We create some log files for diagnostic purposes. (Don't use the builtins for logging. Use the `ticdat` classes instead)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fit_results = run(fit_data, LogFile(\"output_fit.txt\"), LogFile(\"error_fit.txt\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/petercacioppi/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2645: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
        "  VisibleDeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because we did a \"fit\" run, the `fit_results` object consists of a big slab of honking text in the parameters table and not much else."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assert not fit_results.predictions\n",
      "print  \"The length of the big CLOB is %s\"%len(fit_results.parameters[\"fitted CLOB\"][\"value\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The length of the big CLOB is 1832065\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is a big honking string, but lets not be afraid. CSV *should* be ok handling it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "solnFactory.csv.write_directory(fit_results, \"archived_results\", allow_overwrite=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OK, now pretend the whole system took a nice long nappy nap. When it woke up, some user came along and entered data that just so happened to be equivalent to every 10th record (starting with the 6th record) of the original data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_to_predict = dataFactory.TicDat()\n",
      "for i,r in enumerate(fit_data.messages): # messages has no primary key so it is akin to a list\n",
      "    if i%10 == 5:\n",
      "        data_to_predict.messages.append({\"message\":r[\"message\"], \n",
      "                                         \"label\":\"IGNORED BECAUSE I'M NOW GOING TO PREDICT\"})\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The user knows he wants to predict this data, so he sets the parameter correctly."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_to_predict.parameters[\"mode\"] = \"predict\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, the fitted CLOB that we archived before the nap is now going to be recovered and used to recreate the predictor object.\n",
      "\n",
      "(The OCP will have some special gizmos to facilitate this \"what used to be an output is now an input\".)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv # doing some extra magic here to make sure csv works properly...\n",
      "csv.field_size_limit(sys.maxsize) # with our massive field from before\n",
      "recovered_fit_results = solnFactory.csv.create_tic_dat(\"archived_results\")\n",
      "data_to_predict.parameters[\"fitted CLOB\"] = \\\n",
      "    recovered_fit_results.parameters[\"fitted CLOB\"][\"value\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OK, lets see if it works! "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predict_results = run(data_to_predict, \n",
      "                      LogFile(\"output_predict.txt\"), LogFile(\"error_predict.txt\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(predict_results.predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "557"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(predict_results.predictions) == len(data_to_predict.messages)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OK, it looked like something good happened, but lets examine it a little more closely. I'm going to go back and pick out the labels associated with the `data_to_predict` messages."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels = []\n",
      "for i,r in enumerate(fit_data.messages): # messages has no primary key so it is akin to a list\n",
      "    if i%10 == 5:\n",
      "        labels.append(r[\"label\"])\n",
      "assert len(labels) == len(predict_results.predictions) == len(data_to_predict.messages)\n",
      "{_:len([x for x in labels if x == _]) for _ in [\"ham\",\"spam\"]} "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "{'ham': 490, 'spam': 67}"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now I'll just see how well those labels matched up against the predictions. (Again, this notebook isn't focused on rigorous ML methodology. I'm execrising the `ml_spam` file, in the same way you can exercise your own `ticdat` compatible ML engine)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "worked = 0\n",
      "for l,p in zip(labels, predict_results.predictions):\n",
      "    if l == p[\"prediction\"]:\n",
      "        worked += 1\n",
      "print \"It recreated %s out of %s\"%(worked, len(labels))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "It recreated 446 out of 557\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "{_:len([x for x in predict_results.predictions if x[\"prediction\"] == _]) for _ in [\"ham\",\"spam\"]} "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "{'ham': 491, 'spam': 66}"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This seems good enough. Let's recap what we saw here.\n",
      "\n",
      " 1. You make `TicDatFactories` for the input and output schemas, as always.\n",
      " 1. You use things like `sklearn` to do fancy ML work inside of a `run` routine.\n",
      "   1. This `run` routine has two modes, that are read from a parameters table.\n",
      "     1. The fit mode will create a predictor object from a big data set. This predictor object is turned into a string with `cPickle.dumps` and that string is returned as a parameters result in the output schema.\n",
      "     1. The predict mode will look for both a data set and a big parameter string that can be turned into a predictor object with `cPickle.loads`. The recreated predictor object then makes predictions about the input data. These predictions populate the appropriate output schema table.\n",
      " 1. You test this `run` routine with scripts similar to this notebook.\n",
      " 1. The actual file that has `run`, `dataFactory` and `solnFactory` is compatible with Opalytics, and can be deployed on our system."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}