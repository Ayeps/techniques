{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing with pandas, gurobipy.tuplelist, and O(n) slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a little python script that sets up the performance comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run prep_for_different_slicings.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slicing will be over small, medium, and large tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1200, 31800, 270000]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(getattr(td, \"childTable\")) for td in (smallTd, medTd, bigTd)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run three series of four tests each.\n",
    "\n",
    "Each series tests\n",
    " 1. slicing with `.sloc` and `pandas`\n",
    " 1. slicing with `gurobipy.tuplelist`\n",
    " 1. slicing with `ticdat.Slicer` (with the `gurobipy` enhancement disabled)\n",
    " 1. O(n) slicing \n",
    "\n",
    "First, we see that with a small table (1,200) rows, the `pandas` slicing is only somewhat faster than the O(n) slicing, while `Slicer` slicing is quite a bit faster and `tuplelist` faster still."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.59 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkChildDfLen(smallChildDf, *smallChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.71 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "100000 loops, best of 3: 5.26 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkTupleListLen(smallSmartTupleList, *smallChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 23.3 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkSlicerLen(smallSlicer, *smallChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 5.71 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkTupleListLen(smallDumbTupleList, *smallChk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we see that with a table of 31,800 rows, `pandas` slicing is now ~100 faster than O(n) slicing (but `tuplelist` and `Slicer` are still the fastest by far)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.87 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkChildDfLen(medChildDf, *medChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.05 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "100000 loops, best of 3: 5.17 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkTupleListLen(medSmartTupleList, *medChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 25 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkSlicerLen(medSlicer, *medChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 164 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkTupleListLen(medDumbTupleList, *medChk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we see that with a table of 270,000 rows, `pandas` slicing is ~1000X faster than O(n) slicing. Here, `tuplelist` is blindingly fast - nearly as much an improvement shows over `pandas` as `pandas` shows over O(n). `Slicer` again comes in a respectably close second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 4.06 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkChildDfLen(bigChildDf, *bigChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 loops, best of 3: 5.27 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkTupleListLen(bigSmartTupleList, *bigChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 69 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkSlicerLen(bigSlicer, *bigChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 1.42 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkTupleListLen(bigDumbTupleList, *bigChk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottom line? `pandas` isn't really designed with \"iterating over indicies and slicing\" in mind, so it isn't the absolutely fastest way to write this sort of code. However, `pandas` also doesn't implement naive O(n) slicing. \n",
    "\n",
    "For most instances, the `.sloc` approach to slicing will be fast enough. In general, so long as you use the optimal big-O subroutines, the time to solve a MIP or LP model will be larger than the time to formulate the model.  However, in those instances where the slicing is the bottleneck operation, `gurobipy.tuplelist` or `ticdat.Slicer` can be used, or the model building code can be refactored to be more pandonic.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addendum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a request to check `sum` as well as `len`. Here the results vindicate `pandas`, in as much as all three \"smart\" strategies are roughly equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 4.22 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkChildDfSum(bigChildDf, *bigChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 2.9 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkTupleListSum(bigSmartTupleList, bigTd, *bigChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 2.94 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkSlicerSum(bigSlicer, bigTd, *bigChk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 1.42 s per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit checkTupleListSum(bigDumbTupleList, bigTd, *bigChk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
